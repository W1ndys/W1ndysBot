import cv2
import random
import os
import numpy as np
import asyncio
from logger import logger

try:
    from pyzbar import pyzbar

    PYZBAR_AVAILABLE = True
except ImportError:
    PYZBAR_AVAILABLE = False


class VideoQRDetector:
    """
    è§†é¢‘äºŒç»´ç æ£€æµ‹å™¨ç±»ï¼Œæ”¯æŒä»åœ¨çº¿è§†é¢‘é“¾æ¥ä¸­æŠ½å–å¸§å¹¶æ£€æµ‹äºŒç»´ç ã€‚
    """

    def __init__(self, output_dir="output_frames"):
        """
        åˆå§‹åŒ–è§†é¢‘äºŒç»´ç æ£€æµ‹å™¨ã€‚

        Args:
            output_dir (str): ä¿å­˜å›¾ç‰‡çš„ç›®å½•
        """
        # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿ç›®å½•åˆ›å»ºæˆåŠŸ
        self.output_dir = os.path.abspath(output_dir)
        # æ³¨æ„ï¼š__init__ ä¸èƒ½æ˜¯å¼‚æ­¥çš„ï¼Œæ‰€ä»¥è¿™é‡Œå…ˆä¸åˆ›å»ºç›®å½•ï¼Œåœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶åˆ›å»º

        # åˆå§‹åŒ– OpenCV QR ç æ£€æµ‹å™¨ä½œä¸ºå¤‡ç”¨
        try:
            self.qr_detector = cv2.QRCodeDetector()
            self.opencv_qr_available = True
        except:
            self.opencv_qr_available = False

    def _validate_url(self, video_url):
        """
        éªŒè¯è§†é¢‘URLæ˜¯å¦æœ‰æ•ˆã€‚

        Args:
            video_url (str): è§†é¢‘URL

        Returns:
            bool: URLæ˜¯å¦æœ‰æ•ˆ
        """
        if not isinstance(video_url, str):
            return False

        return video_url.startswith(("http://", "https://"))

    async def _ensure_output_dir(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        try:
            if not os.path.exists(self.output_dir):
                # ä½¿ç”¨ asyncio åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œé˜»å¡æ“ä½œ
                await asyncio.get_event_loop().run_in_executor(
                    None, os.makedirs, self.output_dir
                )
                logger.info(f"åˆ›å»ºè¾“å‡ºç›®å½•ï¼š{self.output_dir}")
            else:
                logger.info(f"è¾“å‡ºç›®å½•å·²å­˜åœ¨ï¼š{self.output_dir}")
        except Exception as e:
            logger.error(f"åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥ï¼š{e}")
            # å¦‚æœæ— æ³•åˆ›å»ºæŒ‡å®šç›®å½•ï¼Œä½¿ç”¨å½“å‰ç›®å½•
            self.output_dir = os.getcwd()
            logger.info(f"ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºè¾“å‡ºç›®å½•ï¼š{self.output_dir}")

    async def preprocess_image_for_qr(self, image):
        """
        å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ä»¥æé«˜äºŒç»´ç æ£€æµ‹ç‡ã€‚

        Args:
            image: OpenCVå›¾åƒå¯¹è±¡

        Returns:
            list: é¢„å¤„ç†åçš„å›¾åƒåˆ—è¡¨
        """

        def _process_image():
            processed_images = []

            # 1. åŸå§‹å›¾åƒ
            processed_images.append(("original", image))

            # 2. è½¬æ¢ä¸ºç°åº¦å›¾åƒ
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            processed_images.append(("gray", gray))

            # 3. ç›´æ–¹å›¾å‡è¡¡åŒ–
            equalized = cv2.equalizeHist(gray)
            processed_images.append(("equalized", equalized))

            # 4. å¯¹æ¯”åº¦é™åˆ¶çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ– (CLAHE)
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
            clahe_img = clahe.apply(gray)
            processed_images.append(("clahe", clahe_img))

            # 5. é«˜æ–¯æ¨¡ç³Šåé”åŒ–
            blurred = cv2.GaussianBlur(gray, (3, 3), 0)
            sharpened = cv2.addWeighted(gray, 1.5, blurred, -0.5, 0)
            processed_images.append(("sharpened", sharpened))

            # 6. è‡ªé€‚åº”é˜ˆå€¼å¤„ç†
            adaptive_thresh = cv2.adaptiveThreshold(
                gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
            )
            processed_images.append(("adaptive_thresh", adaptive_thresh))

            # 7. Otsué˜ˆå€¼å¤„ç†
            _, otsu_thresh = cv2.threshold(
                gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
            )
            processed_images.append(("otsu_thresh", otsu_thresh))

            # 8. å½¢æ€å­¦æ“ä½œ
            kernel = np.ones((2, 2), np.uint8)
            morph = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)
            processed_images.append(("morphology", morph))

            # 9. ä¸åŒå°ºå¯¸çš„å›¾åƒ
            height, width = gray.shape
            # æ”¾å¤§å›¾åƒ
            enlarged = cv2.resize(
                gray, (width * 2, height * 2), interpolation=cv2.INTER_CUBIC
            )
            processed_images.append(("enlarged", enlarged))

            # ç¼©å°å›¾åƒ
            if width > 400 and height > 400:
                reduced = cv2.resize(
                    gray, (width // 2, height // 2), interpolation=cv2.INTER_AREA
                )
                processed_images.append(("reduced", reduced))

            # 10. æš—è‰²æ¨¡å¼å¤„ç†ï¼šåè½¬å›¾åƒé¢œè‰²
            # è¿™å¯¹äºæ£€æµ‹æš—è‰²ä¸»é¢˜ä¸‹çš„ç™½è‰²èƒŒæ™¯äºŒç»´ç ç‰¹åˆ«æœ‰æ•ˆ
            inverted = cv2.bitwise_not(gray)
            processed_images.append(("inverted_for_dark_mode", inverted))

            # 11. æš—è‰²æ¨¡å¼ + å¯¹æ¯”åº¦å¢å¼º
            # åè½¬ååº”ç”¨CLAHEæé«˜å¯¹æ¯”åº¦
            inverted_clahe = clahe.apply(inverted)
            processed_images.append(("inverted_clahe", inverted_clahe))

            # 12. æš—è‰²æ¨¡å¼ + è‡ªé€‚åº”é˜ˆå€¼
            # åè½¬ååº”ç”¨è‡ªé€‚åº”é˜ˆå€¼
            inverted_adaptive = cv2.adaptiveThreshold(
                inverted, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
            )
            processed_images.append(("inverted_adaptive", inverted_adaptive))

            # 13. æš—è‰²æ¨¡å¼ + Otsué˜ˆå€¼
            # åè½¬ååº”ç”¨Otsué˜ˆå€¼
            _, inverted_otsu = cv2.threshold(
                inverted, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU
            )
            processed_images.append(("inverted_otsu", inverted_otsu))

            return processed_images

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œå›¾åƒå¤„ç†
        return await asyncio.get_event_loop().run_in_executor(None, _process_image)

    async def detect_qr_codes_pyzbar(self, image):
        """
        ä½¿ç”¨ pyzbar æ£€æµ‹äºŒç»´ç ã€‚

        Args:
            image: OpenCVå›¾åƒå¯¹è±¡

        Returns:
            list: æ£€æµ‹åˆ°çš„äºŒç»´ç ä¿¡æ¯åˆ—è¡¨
        """
        if not PYZBAR_AVAILABLE:
            return []

        def _detect():
            # æ£€æµ‹äºŒç»´ç 
            qr_codes = pyzbar.decode(image)

            results = []
            for qr_code in qr_codes:
                # è·å–äºŒç»´ç æ•°æ®
                qr_data = qr_code.data.decode("utf-8")
                qr_type = qr_code.type

                # è·å–äºŒç»´ç ä½ç½®ä¿¡æ¯
                points = qr_code.polygon
                if len(points) == 4:
                    # è½¬æ¢ä¸ºæ•´æ•°åæ ‡
                    pts = [(int(point.x), int(point.y)) for point in points]
                else:
                    # å¦‚æœä¸æ˜¯å››è¾¹å½¢ï¼Œä½¿ç”¨çŸ©å½¢è¾¹ç•Œ
                    x, y, w, h = qr_code.rect
                    pts = [(x, y), (x + w, y), (x + w, y + h), (x, y + h)]

                results.append(
                    {
                        "data": qr_data,
                        "type": qr_type,
                        "points": pts,
                        "method": "pyzbar",
                    }
                )

            return results

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒäºŒç»´ç æ£€æµ‹
        return await asyncio.get_event_loop().run_in_executor(None, _detect)

    async def detect_qr_codes_opencv(self, image):
        """
        ä½¿ç”¨ OpenCV æ£€æµ‹äºŒç»´ç ã€‚

        Args:
            image: OpenCVå›¾åƒå¯¹è±¡

        Returns:
            list: æ£€æµ‹åˆ°çš„äºŒç»´ç ä¿¡æ¯åˆ—è¡¨
        """
        if not self.opencv_qr_available:
            return []

        def _detect():
            results = []

            # å¦‚æœæ˜¯å½©è‰²å›¾åƒï¼Œè½¬æ¢ä¸ºç°åº¦
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            try:
                # æ£€æµ‹å’Œè§£ç äºŒç»´ç 
                data, points, _ = self.qr_detector.detectAndDecode(gray)

                if data:
                    # è½¬æ¢ç‚¹åæ ‡
                    if points is not None and len(points) > 0:
                        pts = [(int(point[0]), int(point[1])) for point in points[0]]
                    else:
                        pts = []

                    results.append(
                        {
                            "data": data,
                            "type": "QRCODE",
                            "points": pts,
                            "method": "opencv",
                        }
                    )
            except Exception as e:
                print(f"OpenCV QR æ£€æµ‹å‡ºé”™: {e}")

            return results

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒäºŒç»´ç æ£€æµ‹
        return await asyncio.get_event_loop().run_in_executor(None, _detect)

    async def detect_qr_codes(self, image):
        """
        æ£€æµ‹å›¾ç‰‡ä¸­çš„äºŒç»´ç ï¼ˆå¢å¼ºç‰ˆï¼‰ã€‚

        Args:
            image: OpenCVå›¾åƒå¯¹è±¡

        Returns:
            list: æ£€æµ‹åˆ°çš„äºŒç»´ç ä¿¡æ¯åˆ—è¡¨
        """
        all_results = []

        # è·å–é¢„å¤„ç†åçš„å›¾åƒ
        processed_images = await self.preprocess_image_for_qr(image)

        logger.info(f"æ­£åœ¨ä½¿ç”¨ {len(processed_images)} ç§é¢„å¤„ç†æ–¹æ³•æ£€æµ‹äºŒç»´ç ...")

        # å¹¶å‘æ£€æµ‹æ‰€æœ‰é¢„å¤„ç†åçš„å›¾åƒ
        detection_tasks = []

        for method_name, processed_img in processed_images:
            # ä½¿ç”¨ pyzbar æ£€æµ‹
            if PYZBAR_AVAILABLE:
                task = self._detect_with_method(processed_img, method_name, "pyzbar")
                detection_tasks.append(task)

            # ä½¿ç”¨ OpenCV æ£€æµ‹
            if self.opencv_qr_available:
                task = self._detect_with_method(processed_img, method_name, "opencv")
                detection_tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰æ£€æµ‹ä»»åŠ¡å®Œæˆ
        if detection_tasks:
            results_list = await asyncio.gather(*detection_tasks)
            for results in results_list:
                all_results.extend(results)

        # å»é‡ï¼šåŸºäºäºŒç»´ç å†…å®¹å»é‡
        unique_results = []
        seen_data = set()

        for result in all_results:
            if result["data"] not in seen_data:
                seen_data.add(result["data"])
                unique_results.append(result)
                logger.info(
                    f"âœ… æ£€æµ‹åˆ°äºŒç»´ç  (æ–¹æ³•: {result['method']}, é¢„å¤„ç†: {result['preprocess_method']})"
                )
                logger.info(f"    å†…å®¹: {result['data']}")

        return unique_results

    async def _detect_with_method(self, image, method_name, detector_type):
        """
        ä½¿ç”¨æŒ‡å®šæ–¹æ³•å’Œé¢„å¤„ç†æ£€æµ‹äºŒç»´ç çš„è¾…åŠ©å‡½æ•°
        """
        if detector_type == "pyzbar":
            results = await self.detect_qr_codes_pyzbar(image)
        else:
            results = await self.detect_qr_codes_opencv(image)

        for result in results:
            result["preprocess_method"] = method_name

        return results

    def _get_video_name(self, video_url):
        """
        ä»è§†é¢‘URLä¸­æå–è§†é¢‘åç§°ã€‚

        Args:
            video_url (str): è§†é¢‘URL

        Returns:
            str: è§†é¢‘åç§°
        """
        if not self._validate_url(video_url):
            return "invalid_url"

        # ä»URLä¸­æå–æ–‡ä»¶åï¼Œå¦‚æœæ— æ³•æå–åˆ™ä½¿ç”¨é»˜è®¤åç§°
        try:
            filename = video_url.split("/")[-1]
            # ç§»é™¤URLå‚æ•°
            if "?" in filename:
                filename = filename.split("?")[0]
            if "." in filename and len(filename.split(".")[0]) > 0:
                return filename.split(".")[0]
            else:
                return "online_video"
        except:
            return "online_video"

    async def extract_random_frame(self, video_url, save_image=True, mark_qr=True):
        """
        ä»åœ¨çº¿è§†é¢‘ä¸­éšæœºæŠ½å–ä¸€å¸§å¹¶ä¿å­˜ä¸ºå›¾ç‰‡ï¼ŒåŒæ—¶æ£€æµ‹äºŒç»´ç ã€‚

        Args:
            video_url (str): åœ¨çº¿è§†é¢‘é“¾æ¥
            save_image (bool): æ˜¯å¦ä¿å­˜å›¾ç‰‡
            mark_qr (bool): æ˜¯å¦ä¿å­˜æ ‡è®°äº†äºŒç»´ç çš„å›¾ç‰‡

        Returns:
            dict: åŒ…å«æ£€æµ‹ç»“æœçš„å­—å…¸
        """
        # éªŒè¯URL
        if not self._validate_url(video_url):
            logger.error(f"é”™è¯¯ï¼šæ— æ•ˆçš„è§†é¢‘URL {video_url}")
            return {"success": False, "error": "æ— æ•ˆçš„è§†é¢‘URL"}

        def _extract_frame():
            cap = cv2.VideoCapture(video_url)

            if not cap.isOpened():
                logger.error(f"é”™è¯¯ï¼šæ— æ³•æ‰“å¼€è§†é¢‘URL {video_url}")
                return None, {"success": False, "error": "æ— æ³•æ‰“å¼€è§†é¢‘URL"}

            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if total_frames == 0:
                logger.error(f"é”™è¯¯ï¼šè§†é¢‘ {video_url} ä¸åŒ…å«ä»»ä½•å¸§ã€‚")
                cap.release()
                return None, {"success": False, "error": "è§†é¢‘ä¸åŒ…å«ä»»ä½•å¸§"}

            random_frame_index = random.randint(0, total_frames - 1)
            cap.set(cv2.CAP_PROP_POS_FRAMES, random_frame_index)

            ret, frame = cap.read()
            cap.release()

            if not ret:
                logger.error(
                    f"é”™è¯¯ï¼šæœªèƒ½è¯»å–è§†é¢‘ {video_url} ä¸­çš„éšæœºå¸§ {random_frame_index}ã€‚"
                )
                return None, {"success": False, "error": "æ— æ³•è¯»å–è§†é¢‘å¸§"}

            return frame, {
                "success": True,
                "frame_index": random_frame_index,
                "total_frames": total_frames,
            }

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        await self._ensure_output_dir()

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œè§†é¢‘å¸§æå–
        frame, result = await asyncio.get_event_loop().run_in_executor(
            None, _extract_frame
        )

        if not result["success"] or frame is None:
            return result

        # æ£€æµ‹äºŒç»´ç 
        qr_results = await self.detect_qr_codes(frame)

        result.update(
            {
                "has_qr_code": len(qr_results) > 0,
                "qr_codes": qr_results,
            }
        )

        if save_image and frame is not None:
            video_name = self._get_video_name(video_url)
            output_filename = f"frame_{video_name}_{result['frame_index']}.jpg"
            output_path = os.path.join(self.output_dir, output_filename)

            # å¼‚æ­¥ä¿å­˜å›¾ç‰‡
            try:

                def _save_image():
                    return cv2.imwrite(output_path, frame)

                success = await asyncio.get_event_loop().run_in_executor(
                    None, _save_image
                )

                if success:
                    result["image_path"] = output_path
                    logger.info(
                        f"æˆåŠŸå¯¼å‡ºéšæœºå¸§ {result['frame_index']} åˆ°ï¼š{output_path}"
                    )
                    # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                    if os.path.exists(output_path):
                        file_size = os.path.getsize(output_path)
                        logger.info(f"æ–‡ä»¶å¤§å°ï¼š{file_size} å­—èŠ‚")
                    else:
                        logger.warning(f"è­¦å‘Šï¼šæ–‡ä»¶ä¿å­˜åæœªæ‰¾åˆ°ï¼š{output_path}")
                else:
                    logger.error(f"é”™è¯¯ï¼šæ— æ³•ä¿å­˜å›¾ç‰‡åˆ° {output_path}")
                    result["save_error"] = "cv2.imwrite è¿”å› False"
            except Exception as e:
                logger.error(f"ä¿å­˜å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                result["save_error"] = str(e)

        if qr_results:
            logger.info(f"\nğŸ” åœ¨å›¾ç‰‡ä¸­æ£€æµ‹åˆ° {len(qr_results)} ä¸ªäºŒç»´ç ï¼š")
            for i, qr_info in enumerate(qr_results, 1):
                logger.info(f"  äºŒç»´ç  {i}:")
                logger.info(f"    ç±»å‹: {qr_info['type']}")
                logger.info(f"    å†…å®¹: {qr_info['data']}")
                logger.info(f"    ä½ç½®: {qr_info['points']}")

            # å¯é€‰ï¼šåœ¨å›¾ç‰‡ä¸Šæ ‡è®°äºŒç»´ç ä½ç½®å¹¶ä¿å­˜
            if save_image and mark_qr and frame is not None:

                def _create_marked_image():
                    frame_with_qr = frame.copy()
                    for qr_info in qr_results:
                        points = qr_info["points"]
                        # ç»˜åˆ¶äºŒç»´ç è¾¹ç•Œ
                        for i in range(len(points)):
                            cv2.line(
                                frame_with_qr,
                                points[i],
                                points[(i + 1) % len(points)],
                                (0, 255, 0),
                                2,
                            )

                        # åœ¨äºŒç»´ç é™„è¿‘æ·»åŠ æ–‡æœ¬
                        cv2.putText(
                            frame_with_qr,
                            f"QR: {qr_info['data'][:20]}...",
                            (points[0][0], points[0][1] - 10),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.5,
                            (0, 255, 0),
                            1,
                        )
                    return frame_with_qr

                frame_with_qr = await asyncio.get_event_loop().run_in_executor(
                    None, _create_marked_image
                )

                # ä¿å­˜æ ‡è®°äº†äºŒç»´ç çš„å›¾ç‰‡
                video_name = self._get_video_name(video_url)
                marked_filename = (
                    f"frame_{video_name}_{result['frame_index']}_marked.jpg"
                )
                marked_path = os.path.join(self.output_dir, marked_filename)

                try:

                    def _save_marked_image():
                        return cv2.imwrite(marked_path, frame_with_qr)

                    success = await asyncio.get_event_loop().run_in_executor(
                        None, _save_marked_image
                    )

                    if success:
                        result["marked_image_path"] = marked_path
                        logger.info(f"å·²ä¿å­˜æ ‡è®°äºŒç»´ç çš„å›¾ç‰‡åˆ°ï¼š{marked_path}")
                        # éªŒè¯æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                        if os.path.exists(marked_path):
                            file_size = os.path.getsize(marked_path)
                            logger.info(f"æ ‡è®°å›¾ç‰‡æ–‡ä»¶å¤§å°ï¼š{file_size} å­—èŠ‚")
                    else:
                        logger.error(f"é”™è¯¯ï¼šæ— æ³•ä¿å­˜æ ‡è®°å›¾ç‰‡åˆ° {marked_path}")
                except Exception as e:
                    logger.error(f"ä¿å­˜æ ‡è®°å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
        else:
            logger.error("âŒ æœªåœ¨å›¾ç‰‡ä¸­æ£€æµ‹åˆ°äºŒç»´ç ")

        return result

    async def has_qr_code(self, video_url, num_samples=3):
        """
        æ£€æŸ¥åœ¨çº¿è§†é¢‘æ˜¯å¦åŒ…å«äºŒç»´ç ã€‚

        Args:
            video_url (str): åœ¨çº¿è§†é¢‘é“¾æ¥
            num_samples (int): é‡‡æ ·å¸§æ•°ï¼Œé»˜è®¤æ£€æŸ¥3å¸§

        Returns:
            bool: å¦‚æœåœ¨ä»»ä½•ä¸€å¸§ä¸­æ£€æµ‹åˆ°äºŒç»´ç åˆ™è¿”å›True
        """
        # éªŒè¯URL
        if not self._validate_url(video_url):
            logger.error(f"é”™è¯¯ï¼šæ— æ•ˆçš„è§†é¢‘URL {video_url}")
            return False

        def _sample_frames():
            cap = cv2.VideoCapture(video_url)

            if not cap.isOpened():
                logger.error(f"é”™è¯¯ï¼šæ— æ³•æ‰“å¼€è§†é¢‘URL {video_url}")
                return []

            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if total_frames == 0:
                logger.error(f"é”™è¯¯ï¼šè§†é¢‘ {video_url} ä¸åŒ…å«ä»»ä½•å¸§ã€‚")
                cap.release()
                return []

            # éšæœºé‡‡æ ·å¤šå¸§è¿›è¡Œæ£€æµ‹
            sample_frames = random.sample(
                range(total_frames), min(num_samples, total_frames)
            )

            frames = []
            for frame_index in sample_frames:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
                ret, frame = cap.read()

                if ret:
                    frames.append((frame_index, frame))

            cap.release()
            return frames

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œè§†é¢‘å¸§é‡‡æ ·
        frames = await asyncio.get_event_loop().run_in_executor(None, _sample_frames)

        if not frames:
            return False

        # å¹¶å‘æ£€æµ‹æ‰€æœ‰é‡‡æ ·å¸§
        detection_tasks = []
        for frame_index, frame in frames:
            task = self._check_frame_for_qr(frame_index, frame)
            detection_tasks.append(task)

        results = await asyncio.gather(*detection_tasks)

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•å¸§åŒ…å«äºŒç»´ç 
        for frame_index, has_qr in results:
            if has_qr:
                logger.info(f"âœ… åœ¨ç¬¬ {frame_index} å¸§æ£€æµ‹åˆ°äºŒç»´ç ")
                return True

        logger.error(f"âŒ åœ¨ {len(frames)} ä¸ªé‡‡æ ·å¸§ä¸­æœªæ£€æµ‹åˆ°äºŒç»´ç ")
        return False

    async def _check_frame_for_qr(self, frame_index, frame):
        """
        æ£€æŸ¥å•ä¸ªå¸§æ˜¯å¦åŒ…å«äºŒç»´ç çš„è¾…åŠ©å‡½æ•°
        """
        qr_results = await self.detect_qr_codes(frame)
        return frame_index, len(qr_results) > 0


async def main():
    """å¼‚æ­¥ä¸»å‡½æ•°ç¤ºä¾‹"""
    # åˆ›å»ºæ£€æµ‹å™¨å®ä¾‹
    detector = VideoQRDetector()

    # åœ¨çº¿è§†é¢‘é“¾æ¥ç¤ºä¾‹
    video_url = "https://multimedia.nt.qq.com.cn:443/download?appid=1415&format=origin&orgfmt=t264&spec=0&client_proto=ntv2&client_appid=537290727&client_type=linux&client_ver=3.2.17-34740&client_down_type=auto&client_aio_type=aio&rkey=CAMSoAGKDKztJ3o-DuZWsqllLFaCETK5dfWJ69wEuQ1AC5EyZQ3a3zLuxXz50N35pxCqhZwNqfNJzu3cubFB59_LfSEr8DBQkkzxcJQTpbMv9Fk6GZUqTGS_OW_ijMu-PZjzYm6IX9T5tmTF6-eCUs3HiOucF7LJeccAKH4DSKS6Aqm_9tQpyXmef2LSgX-7xn7GOUjEkq0c_HiC87yKwE9QeFsi"

    # éªŒè¯URLæ ¼å¼
    if not detector._validate_url(video_url):
        logger.error(f"é”™è¯¯ï¼šæ— æ•ˆçš„è§†é¢‘URLæ ¼å¼")
        return

    # æ£€æŸ¥æ˜¯å¦åŒ…å«äºŒç»´ç 
    has_qr = await detector.has_qr_code(video_url)
    logger.info(f"\nè§†é¢‘æ˜¯å¦åŒ…å«äºŒç»´ç : {has_qr}")

    # æŠ½å–éšæœºå¸§å¹¶æ£€æµ‹äºŒç»´ç 
    result = await detector.extract_random_frame(video_url)

    if result["success"]:
        logger.info(f"\næ£€æµ‹ç»“æœ:")
        logger.info(f"  æ€»å¸§æ•°: {result['total_frames']}")
        logger.info(f"  æŠ½å–å¸§ç´¢å¼•: {result['frame_index']}")
        logger.info(f"  åŒ…å«äºŒç»´ç : {result['has_qr_code']}")
        if result["has_qr_code"]:
            logger.info(f"  äºŒç»´ç æ•°é‡: {len(result['qr_codes'])}")

        # æ˜¾ç¤ºä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        if "image_path" in result:
            logger.info(f"  ä¿å­˜çš„å›¾ç‰‡è·¯å¾„: {result['image_path']}")
        if "marked_image_path" in result:
            logger.info(f"  æ ‡è®°å›¾ç‰‡è·¯å¾„: {result['marked_image_path']}")
        if "save_error" in result:
            logger.info(f"  ä¿å­˜é”™è¯¯: {result['save_error']}")

    logger.info("\nå®Œæˆï¼")
    logger.info(f"ä½ å¯ä»¥åœ¨ '{detector.output_dir}' æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°å¯¼å‡ºçš„å›¾ç‰‡ã€‚")
    logger.info("è¯·ç¡®ä¿å®‰è£…äº†ä»¥ä¸‹ä¾èµ–ï¼š")
    logger.info("  pip install opencv-python")
    logger.info("  pip install pyzbar")


if __name__ == "__main__":
    asyncio.run(main())
